{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "lastEditStatus": {
   "notebookId": "wexdiba2y4g2lehxkfwc",
   "authorId": "5713202290",
   "authorName": "TIMBURNSOWLMTN1",
   "authorEmail": "timburnsowlmtn@gmail.com",
   "sessionId": "365bb9da-712e-4148-ab39-a327f50422ec",
   "lastEditTime": 1746893538049
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {
    "name": "cell1",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n\n# Import python packages\nimport streamlit as st\nimport pandas as pd  #%%\n# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n\nsales = session.table(\"SALES\").to_pandas()\npurchase = session.table(\"PURCHASES\").to_pandas()\ninvoice = session.table(\"INVOICE_PURCHASE\").to_pandas()\nend_inv = session.table(\"END_INV\").to_pandas()\nbeg_inv = session.table(\"BEG_INV\").to_pandas()\ndisplay(beg_inv.head())\ndisplay(end_inv.head())\n\n\n\n     ",
   "id": "7a23888c-09cf-4a82-a3cf-091e014e72dd"
  },
  {
   "cell_type": "code",
   "id": "9e11e8f1-68d2-4939-975f-65301965ce4c",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "\nnuniques = {\"beg_inv\": beg_inv.nunique(), \"end_inv\": end_inv.nunique()}\ndisplay(\n    pd.DataFrame(nuniques).T[\n        [\n            \"INVENTORYID\",\n            \"STORE\",\n            \"CITY\",\n            \"BRAND\",\n            \"DESCRIPTION\",\n            \"SIZE\",\n            \"ONHAND\",\n            \"BEGINDATE\",\n            \"ENDDATE\",\n        ]\n    ]\n)\nprint(\n    f\"BEG_INV BRAND nunique: {beg_inv.BRAND.nunique()}, desc + size nunique: {(beg_inv['DESCRIPTION'] + ' ' + beg_inv['SIZE']).nunique()}??? Might need cleaning\"\n)\nprint(\n    f\"end_inv Brand nunique: {end_inv.BRAND.nunique()}, desc + size nunique: {(end_inv['DESCRIPTION'] + ' ' + end_inv['SIZE']).nunique()}\"\n)\nbeg_inv_brand = beg_inv.loc[:]\nbeg_inv_brand[\"DESC_SIZE\"] = beg_inv_brand[\"DESCRIPTION\"] + \" \" + beg_inv_brand[\"SIZE\"]\ngroup_desc = (\n    beg_inv_brand[[\"BRAND\", \"DESC_SIZE\"]].groupby(\"DESC_SIZE\")[\"BRAND\"].unique()\n)\ngroup_desc.loc[group_desc.apply(len) > 1]\n\ndisplay(sales.head())\ndisplay(\n    beg_inv.loc[\n        (beg_inv[\"BRAND\"] == 1004) & (beg_inv[\"INVENTORYID\"] == \"1_HARDERSFIELD_1004\")\n        ]\n)\n# ? Inventory ID = store_city_brand, Brand = description + Size, With Inventory ID we can find how many onhand the inventory have at the beginning and end.\nprint(sales.CLASSIFICATION.unique())",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29eca113-4c91-46c1-bf68-44ca0c8fc962",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "## 1. Aggregate the data from the tables\n\n- **Group** the `sales` DataFrame by the `\"SALESDATE\"` column.  \n- **Aggregate** by summing `\"SALESQUANTITY\"` to get total daily sales.  \n- Result stored in a new DataFrame `sales_quantity_price`.\n\n"
  },
  {
   "cell_type": "code",
   "id": "0989e51c-30ca-4c49-9f68-06a2873a3f2f",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "# * group by date, sum sales quantity to get total sales quantity per day\nsales_quantity_price = sales.groupby(\"SALES_DATE\").agg({\"SALES_QUANTITY\": \"sum\"})\n\nsales_quantity_price.describe();\n\nprint(sales_quantity_price);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5098f37-d49d-4c1f-8451-190a69d21554",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "\n\n## 2. Native Snowflake ML Forecasting\n\nSnowflake provides built-in time-series forecasting as a SQL object you train and invoke entirely in SQL"
  },
  {
   "cell_type": "code",
   "id": "88441f5b-8760-46e0-840c-5e46d600f91a",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "df_to_write = sales_quantity_price.reset_index()\n\n\nsnowpark_df = session.create_dataframe(df_to_write)  \nsnowpark_df.write.mode(\"overwrite\").save_as_table(\"SALES_QUANTITY_PRICE\");\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99d651f9-cf69-4b1c-83ee-c87d456f153a",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "-- 1) Train the model (requires CREATE SNOWFLAKE.ML.FORECAST privilege)\nCREATE SNOWFLAKE.ML.FORECAST inventory_forecast_model (\n  INPUT_DATA       => TABLE(sales_quantity_price),\n  TIMESTAMP_COLNAME=> 'SALES_DATE',\n  TARGET_COLNAME   => 'SALES_QUANTITY'\n);\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15fe47c8-bb69-4239-925d-465f7136da9c",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "-- 2) Generate a 90-day forecast\nCREATE or REPLACE table sales_quantity_price_forecast AS\nSELECT * \nFROM TABLE(inventory_forecast_model!FORECAST(FORECASTING_PERIODS => 90));",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "765e9257-4cf4-43be-8c20-a04227b0a915",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "# â”€â”€ 2) Load your tables into pandas (using SALES_DATE & SALES_QUANTITY) â”€â”€â”€â”€â”€â”€â”€â”€â”€\nsales_df = (\n    session\n    .table(\"SALES\")\n    .select(\"SALES_DATE\", \"SALES_QUANTITY\")\n    .to_pandas()\n)\nsq_df = (\n    session\n    .table(\"SALES_QUANTITY_PRICE\")\n    .select(\"SALES_DATE\", \"SALES_QUANTITY\")\n    .to_pandas()\n)\n\n# Ensure the date columns are datetime\nsales_df[\"SALES_DATE\"] = pd.to_datetime(sales_df[\"SALES_DATE\"])\nsq_df[\"SALES_DATE\"]    = pd.to_datetime(sq_df[\"SALES_DATE\"])\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb22e1ae-d866-43f2-af38-c618d127b4eb",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n# â”€â”€ 3) Merge on SALES_DATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmerged = pd.merge(\n    sales_df.rename(columns={\"SALES_QUANTITY\": \"Raw_Sales\"}),\n    sq_df.rename(columns={\"SALES_QUANTITY\": \"Agg_Sales\"}),\n    on=\"SALES_DATE\",\n    how=\"inner\"\n)\n# Rename for plotting\nmerged = merged.rename(columns={\"SALES_DATE\": \"Date\"}).set_index(\"Date\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10884a6e-5f2b-4b88-9bd8-4b3942e7c575",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "\n\n# 4) Render with Streamlit\nst.title(\"ðŸ“ˆ Raw vs Aggregated Sales Quantity\")\nst.line_chart(merged.iloc[::32])",
   "execution_count": null
  }
 ]
}