{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "lastEditStatus": {
   "notebookId": "wexdiba2y4g2lehxkfwc",
   "authorId": "5713202290",
   "authorName": "TIMBURNSOWLMTN1",
   "authorEmail": "timburnsowlmtn@gmail.com",
   "sessionId": "371e048b-4839-4284-b521-c6f7a902f4a9",
   "lastEditTime": 1746877883211
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {
    "name": "cell1",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n\n# Import python packages\nimport streamlit as st\nimport pandas as pd  #%%\n# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n\nsales = session.table(\"SALES\").to_pandas()\npurchase = session.table(\"PURCHASES\").to_pandas()\ninvoice = session.table(\"INVOICE_PURCHASE\").to_pandas()\nend_inv = session.table(\"END_INV\").to_pandas()\nbeg_inv = session.table(\"BEG_INV\").to_pandas()\ndisplay(beg_inv.head())\ndisplay(end_inv.head())\n\n\n\n     ",
   "id": "7a23888c-09cf-4a82-a3cf-091e014e72dd"
  },
  {
   "cell_type": "code",
   "id": "9e11e8f1-68d2-4939-975f-65301965ce4c",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "\nnuniques = {\"beg_inv\": beg_inv.nunique(), \"end_inv\": end_inv.nunique()}\ndisplay(\n    pd.DataFrame(nuniques).T[\n        [\n            \"INVENTORYID\",\n            \"STORE\",\n            \"CITY\",\n            \"BRAND\",\n            \"DESCRIPTION\",\n            \"SIZE\",\n            \"ONHAND\",\n            \"BEGINDATE\",\n            \"ENDDATE\",\n        ]\n    ]\n)\nprint(\n    f\"BEG_INV BRAND nunique: {beg_inv.BRAND.nunique()}, desc + size nunique: {(beg_inv['DESCRIPTION'] + ' ' + beg_inv['SIZE']).nunique()}??? Might need cleaning\"\n)\nprint(\n    f\"end_inv Brand nunique: {end_inv.BRAND.nunique()}, desc + size nunique: {(end_inv['DESCRIPTION'] + ' ' + end_inv['SIZE']).nunique()}\"\n)\nbeg_inv_brand = beg_inv.loc[:]\nbeg_inv_brand[\"DESC_SIZE\"] = beg_inv_brand[\"DESCRIPTION\"] + \" \" + beg_inv_brand[\"SIZE\"]\ngroup_desc = (\n    beg_inv_brand[[\"BRAND\", \"DESC_SIZE\"]].groupby(\"DESC_SIZE\")[\"BRAND\"].unique()\n)\ngroup_desc.loc[group_desc.apply(len) > 1]\n\ndisplay(sales.head())\ndisplay(\n    beg_inv.loc[\n        (beg_inv[\"BRAND\"] == 1004) & (beg_inv[\"INVENTORYID\"] == \"1_HARDERSFIELD_1004\")\n        ]\n)\n# ? Inventory ID = store_city_brand, Brand = description + Size, With Inventory ID we can find how many onhand the inventory have at the beginning and end.\nprint(sales.CLASSIFICATION.unique())",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29eca113-4c91-46c1-bf68-44ca0c8fc962",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "## 1. Aggregate the data from the tables\n\n- **Group** the `sales` DataFrame by the `\"SALESDATE\"` column.  \n- **Aggregate** by summing `\"SALESQUANTITY\"` to get total daily sales.  \n- Result stored in a new DataFrame `sales_quantity_price`.\n\n"
  },
  {
   "cell_type": "code",
   "id": "0989e51c-30ca-4c49-9f68-06a2873a3f2f",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "# * group by date, sum sales quantity to get total sales quantity per day\nsales_quantity_price = sales.groupby(\"SALES_DATE\").agg({\"SALES_QUANTITY\": \"sum\"})\n\nsales_quantity_price.describe();\n\nprint(sales_quantity_price);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5098f37-d49d-4c1f-8451-190a69d21554",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "\n\n## 2. Native Snowflake ML Forecasting\n\nSnowflake provides built-in time-series forecasting as a SQL object you train and invoke entirely in SQL"
  },
  {
   "cell_type": "code",
   "id": "88441f5b-8760-46e0-840c-5e46d600f91a",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "df_to_write = sales_quantity_price.reset_index()\n\n\nsnowpark_df = session.create_dataframe(df_to_write)  \nsnowpark_df.write.mode(\"overwrite\").save_as_table(\"SALES_QUANTITY_PRICE\");\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99d651f9-cf69-4b1c-83ee-c87d456f153a",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "-- 1) Train the model (requires CREATE SNOWFLAKE.ML.FORECAST privilege)\nCREATE SNOWFLAKE.ML.FORECAST inventory_forecast_model (\n  INPUT_DATA       => TABLE(sales_quantity_price),\n  TIMESTAMP_COLNAME=> 'SALES_DATE',\n  TARGET_COLNAME   => 'SALES_QUANTITY'\n);\n\n-- 2) Generate a 31-day forecast\nSELECT * \nFROM TABLE(inventory_forecast_model!FORECAST(FORECASTING_PERIODS => 31));",
   "execution_count": null
  }
 ]
}